import pandas as pd

2 basic pandas data structures: Series and DataFrames
Series: one dimensional array, somewhere between a list and a dictionary. Like lists, except they have an associated array of data labels instead of just index locations. Single indexed column of data. Items are stored in an order and there are labels with which they can be retrieved.

list a = [1,2,3]
x=pd.series(list, index=['First','Second','Third']) # stores a list of 3 numbers and labels them, so they can be retrieved either by x[index] or x.label.

underneath, pandas stores data in a numpy typed array. Numbers are stored by default as float64, strings as object.
Dictionaries can also be converted to pandas Series, no need to label.

a = pd.Series([1,2,3,4]) # converts a list to a series
b = pd.Series([1,2,3,4], index=['a','b','c','d']) # creates the same series, but now with custom index labels
a.values # prints the values of the Series
b.index # prints the indexes
b[['c','a','d']] # returns correponding values
Numpy operations like filtering with boolean array, scalar multiplication, math functions etc. apply to Series as well.
Dicts can be converted to Series as:
Series(<dict variable>) # where dict var is {'key1': 'val1', 'key2':'val2' etc}
Series with the same indexes can be aligned (values summed)
A Series' index can be altered in place by assignment to object.index eg. a.index = ['w', 'x', 'y', 'z'] 

a.isnull() will show as True any keys that have no value

Vectorization: do an operation on all elements of a data structure without looping.
np.sum(a) # will calculate the sum of all elements in the series a without looping through them
much faster than looping
###################################
DataFrame: Tabular, spreadsheet like data structure containing an ordered collection of columns each of which can be a different value type (numeric, string, bool etc)

In general, you could say that the Pandas data frame consists of three main components: the data, the index, and the columns.

A dict of equal length lists can be converted to a DataFrame
data = {'state': ['OH','OH', 'OH', 'NV', 'NV'], 
	'year':[2000,2001,2002,2001,2002], 
	'pop': [1.5,1.7,3.6,2.4,2.9]}

df = DataFrame(data)
df = DataFrame(data, columns=[<list of data columns in order you want>])
df.index =[<list of row names you want>] # will name the rows
# all in one shot
df  = pd.DataFrame(data, columns=[<list of col names>], index=[<list of row names>])

Columns can be pulled out either as df['column'] or df.column
df.columns gives the column names and types
Rows can be selected by df.ix[<rownum>]
Rows can be named with the 'index' function:
df.index=['a','b','c','d'] will give these letter as rownames and can be retrived by df.ix['a'] etc.
df.iloc[index] # used to retrieve by index, same as df[index] or df.ix[index]
df.loc['label'] # used to retrieve by label, same as df['label']

A data frame can be formed by combining a set of equal length pd.Series, ndarrays, lists or dicts of lists (in which the keys will automatically be the column names as above
df = pd.DataFrame([series1, series2, series3])
df2 = df.append(<list>) # will create y adding a new list to df, but won't change df

#Access data based on labels (row/column names)
df.loc[rowname/id, colname] # will pull out the value in that cell, same as R data.frame
df.loc[:,[col1, col2]] # pulls out all rows for the 2 cols mentioned

# To slice a chunk (some number of rows for a certain set of columns)
df.loc[fromrowid:torowid, fromcolumn:tocolumn]
# to get all rows for a select set of columns, use a single colon for rows
df.loc[:, 'fromcolumn':'tocolumn']

# copy/delete columns
df.drop(row) # won't drop the row from the original df
df.drop(row, inplace=True) # will drop from original
df.drop(df[index], inplace=True) # better general syntax
df.drop(df.index[:2], inplace=True) # drops first 2 rows
df.drop(df['column'], axis=1 inplace=True) # drops a column by name

del df[col] # deletes columnn

df.columns - gives list of columns
list(df.columns) # gives the column names as a list
list(df) # short version of above

df.shape # gives number or rows and columns in a data frame

df.unstack('column') # splits a dataframe according the values of the column specified

df.T will transpose the data frame

#pandas methods to read files:
pd.read_csv('filename') # optional sep parameter if separator is not comma
pd.read_json('filename')
pd.read_excel('filename', sheetname=0) # to read the first sheet in case there are multiple sheets
#An url can also be passed as argument to the above functions

df = pd.read_csv('file.csv', index_col=0, skiprows=1) # read a csv file, skip the first row and use the first col as index
df = pd.read_table('file.dat', sep='<record separator>', header='<None or row#>', names='<list of names for cols>')

# rename columns 2 ways
df.columns=[<list of new column names>]
df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'}, inplace=True)

#To index with a specific column
df.set_index('colname') 
# above does not change the dataframe, just spits out a modified df. To actually change the df:
df = df.set_index('column') #or
df.set_index('column', inplace=TRUE)
df.set_index([list of cols]) # index with multiple columns
df = df.reset_index() # will reset index

#Access data based on indexes/positions
df.iloc[1:4, 3:5] # fetches rows 1,2 and 3 of column numbers 3&4

#For access with a mix of labels and positions, use ix
df.ix[1:4, 'fromcolumn':'tocolumn']

#To delete a row or column from data frame
df.drop('colname', 1, inplace=True) # 1 means column 
df.drop('rowname', 0, inplace=True) # 0 means row
#To delete by index instead of names/labels
df.drop(df.index[from:to, 0] # change to 1 for columns

#To add a column to a data frame
df['newcolumn'] = "value" # value will be propagated through all the rows of the data frame
# if the values are different, they need to be a list

#To add a new row, transpose the df, add a column and then transpose back

#To apply a function to all rows of a column without looping
df['column'].apply(functionname)
#function can also be a lambda
df['newcolumn'] = df['oldcolumn'].apply(lambda x: <do something with x>)
For eg.
df['column'].apply(lambda x: x+2) # will add 2 to the value of 'column' in all the rows

Querying a DataFrame:
By creating boolean arrays
df[col] > 0 # will create a boolean array where every entry that satisfies the condition will be true and the rest false. This array can be super-imposed on the dataframe to query with the 'where' clause:

df.where(df[col] > 0) # same as in R
df[df[col]>0] # same as above

df[col].unique() # unique values from a col
df = df[df[col] == <some value>] # recreates the data frame with only those entries that satisfy the condition
df = df[<list of cols to keep>] # edits dataframe to drop all other cols

Missing values:
df.fillna(method = 'ffill')

-----------------------------
Merging data frames:

Two merge 2 different data frames which share an index. For eg. a df of staff and students can be merged if the 'name' is a shared index.
pd.merge is the function that does all the merging

pd.merge(first_df, second_df, how='outer', left_index=True, right_index=True) # union merge/outer join
the columns that are not common are put adjacent to each other with NaN where values don't exist.

pd.merge(first_df, second_df, how='inner', left_index=True, right_index=True) # intersection merge/inner join
pd.merge(first_df, second_df, how='left', left_index=True, right_index=True) # left join takes all from the first that also exists in the second
pd.merge(first_df, second_df, how='right', left_index=True, right_index=True) # right join opposite of left
print(pd.merge(df1, df2, left_index=True, right_on=<shared index>))
-----------------------------
Pandas idioms
Index chaining is bad - back to back square brackets as in df.loc[row][column]
Method chaining is recommended - for eg.
(df.where(column == value)
    .dropna()
    .setindex(....)
    .rename(...))
if you begin a statement with (, in python, you can span a statement over mutliple lines.

Pandas has an apply() function that works much the same way as R apply.
apply() lets you execute a function along a certain axis (row or col)
df.apply(<func>, axis=1) # func could be a lambda
